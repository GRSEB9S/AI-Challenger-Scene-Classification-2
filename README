代码说明：

	AIC_scene_data.py构建数据集，目前实现了ai_challenger_train数据集，日后应增加Places365_standard数据集，以及LSUN数据集，或者合并成一个数据集，具体做法参加torch.utils.data.dataset.ConcatDataset类。

	1\ densenet_cosine_264_k48.py
	2\ resnet152_places365_scratch.py
	3\ resnet50_places365_scratch.py
	4\ resnext_101_32x4d.py
	5\ resnext_101_64x4d.py
	6\ resnext_50_32x4d.py
	为预训练模型架构定义文件。
	注意！！
	2\3模型为Places365_standard预训练模型，没有经过ImageNet预训练。
	1\4\5\6为imageNet预训练模型。没有经过Places365数据集训练。
	以上所有模型均来自torch模型，使用torch2pytorch convertor(https://github.com/clcarwin/convert_torch_to_pytorch)转为pytorch模型，1\4\5\6已经原作者证实可以复现ImageNet上的结果。2\3未经证实。

	AIC_scene_train.py为训练代码。	

新增：
	本地使用tensorboard:
		首先运行python3 AIC_scene_train.py --gpus 4 --model ResNet50 --depth 32
		其次另外本地打开一个终端：
		ssh -L 16006:127.0.0.1:6006 username@server_address
		我的就是chaoyang@10.65.1.181，这句命令就是将本地16006端口和服务器6006端口连接起来，tensorboard默认是在6006端口输出数据。
		然后进入到AIC_scene_train.py文件的目录下
		tensorboard --logdir=runs/ --port=6006
		之后，你每运行一次AIC_scene_train.py文件，runs目录下就会自动生成对该run的事件文件。
		然后打开浏览器：输入http://127.0.0.1:16006就可以看到训练中的数据了。
		目前实现了loss prec@k，权重的分布。不推荐加入绘图，会导致程序卡死。

	fine-tune：
		目前实现了ResNet50 和ResNet152 ，可选择的--depth导入模型代码下面有注释。--depth表示fine-tune的深度，从最后一层算起。

实验：
	1、数据量给模型带来的性能提升(fine-tune,非fine-tune无法看出数据量的效果)：
		ImageNet(1400W images,1000 object classes)：places365_caffe(official)目前未测试
		Place2_standard(160W images): 从ResNet50_lr1.0_bs256_depth32来看与非fine-tune相差不大，从ResNet50_lr1.0_bs256_depth87和ResNet_depth32相比，fine-tune深度越大，效果越差。
		AIC_scene(5.3W images)：

	2、网络架构带来的性能提升：
		vgg16(导师跑的) top3准确率是90， top1准确率在76左右。与ResNet50相比差了2个百分点。
		ResNet50_lrdecay30_bs256_lr0.1和ResNext50_lrdecay30_bs256_lr0.1来看，ResNext50 top3是91.756，ResNet50 top3 接近92，两者相差不大。
		从ResNext1101_lrdecay30_bs128_lr0.1来看，top3最高准确率是87.205，与ResNext50相差5个百分点。batchsize从ResNet50_lrdecay15_bs128_lr0.1与ResNet50_lrdecay30_bs256_lr0.1两个模型来看，top3准确率都维持在92%左右，batchsize对模型能否找到全局最优点相差不大。
		目前方向：
	3、其他提升
		


